{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from util_funcs import *\n",
    "from data_processors import *\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification, BertConfig, WEIGHTS_NAME, CONFIG_NAME\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, warmup_linear\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from distortions import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = processors['sst-2']()\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO, \n",
    "                    filename=f\"log_dir/{get_log_name()}.txt\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_config = dict(data_dir = \"glue_data/SST-2\",\n",
    "                      bert_model = \"bert-base-uncased\",\n",
    "                      output_mode = \"classification\",\n",
    "                      max_seq_length = 64,\n",
    "                      local_rank = -1,\n",
    "                      batch_size = 32,\n",
    "                      num_train_epochs = 3,\n",
    "                      do_lower_case=True,\n",
    "                      do_train=True,\n",
    "                      train_batch_size=32,\n",
    "                      gradient_accumulation_steps = 1,\n",
    "                      n_gpu = 1,\n",
    "                      learning_rate = 5e-5,\n",
    "                      logger=logger,\n",
    "                      warmup_proportion = 0.1)\n",
    "locals().update(runtime_config)\n",
    "assert train_batch_size == batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list, num_labels, tokenizer, train_examples, \\\n",
    "           num_train_optimization_steps, train_dataloader = get_data(processor, runtime_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_optimization_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruning was every 10 for the first round of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75830f1cd314448ba7ce1c2e5d1d250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e9b940a08d4aee94df4f57543299b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=2105, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for svd_dim in [50,100,150,200,300]:\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "    bert_model, num_labels=num_labels).to(device).train()\n",
    "\n",
    "    optimizer = get_optimizer(\n",
    "        model, num_train_optimization_steps=num_train_optimization_steps, \n",
    "        **runtime_config)\n",
    "    \n",
    "    tensorboard_log_dir = \"tensorboard_data/\"\n",
    "    output_dir = f\"output/deeptwist/svd{svd_dim}_{get_log_name()}/\"\n",
    "#     try:\n",
    "    os.mkdir(output_dir)\n",
    "#     except:\n",
    "#         os.rmdir(output_dir)\n",
    "#         os.mkdir(output_dir)\n",
    "\n",
    "    report_frequency = 5\n",
    "    twist_frequency = 200\n",
    "    twist_args = dict(k=svd_dim)\n",
    "    distort = svd_compress\n",
    "\n",
    "    counter = 0        \n",
    "    total_period_loss = 0\n",
    "    tb_writer = SummaryWriter(log_dir=tensorboard_log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    nb_tr_steps = 0\n",
    "    tr_loss = 0\n",
    "    for _ in tqdm(range(int(num_train_epochs)), desc=\"Epoch\"):\n",
    "        try:\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "                # define a new function to compute loss values for both output_modes\n",
    "                logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "                if output_mode == \"classification\":\n",
    "                    loss_fct = CrossEntropyLoss()\n",
    "                    loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "                elif output_mode == \"regression\":\n",
    "                    loss_fct = MSELoss()\n",
    "                    loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "                if gradient_accumulation_steps > 1:\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "                tr_loss += loss.item()\n",
    "\n",
    "                # Log to tensorboard\n",
    "                counter += 1\n",
    "                total_period_loss += loss.item()\n",
    "                if counter % report_frequency == 0 and counter > report_frequency:\n",
    "                    writer_callback(counter, total_period_loss / report_frequency, \n",
    "                                    tb_writer, run_name=output_dir.replace(\"/\", \"_\"))\n",
    "                    total_period_loss = 0\n",
    "\n",
    "                nb_tr_examples += input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "                # Deep twist\n",
    "                if counter % twist_frequency == 0 and counter > 0 and twist_frequency > 0:\n",
    "                    state_dict = distort(model.cpu().state_dict(), **twist_args)\n",
    "                    model.load_state_dict(state_dict)\n",
    "    #                 num_zeros = 0\n",
    "    #                 for name, el in model.state_dict().items():\n",
    "    #                     num_zeros += (el == 0).sum().item()\n",
    "    #                 print(num_zeros)\n",
    "                    model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "    save_model(model, output_dir)\n",
    "    tb_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
